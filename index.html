<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Multimodal Deep Learning for Improved Disease Diagnosis
    in Ophthalmology</title>
  <link rel="icon" type="image/x-icon" href="static/images/eye-care.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Multimodal Deep Learning for Improved Disease Diagnosis
              in Ophthalmology</h1>
            </div>
            </div>
            </div>
            </div>
            </section>


            
    <section class="section hero is-light">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
          <h2 class="title is-2">Fundus-Enhanced Disease-Aware Distillation Model for Retinal Disease Classification from OCT Images</h2>
            
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://luxuriant0116.github.io/" target="_blank">Lehan Wang</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=4iTfHyQAAAAJ&hl=en" target="_blank">Weihang Dai</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://multi-eye.github.io/" target="_blank">Mei Jin</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://multi-eye.github.io/" target="_blank">Chubin Ou</a><sup>3</sup>,</span>
                  <span class="author-block">
                    <a href="https://xmengli.github.io/" target="_blank">Xiaomeng Li</a><sup>*</sup><sup>1</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>The Hong Kong University of Science and Technology<br><sup>2</sup>Guangdong Provincial Hospital of Integrated
                      Traditional Chinese and Western Medicine<br><sup>3</sup>Guangdong Weiren Meditech Co., Ltd</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2308.00291" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/xmed-lab/FDDM" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

            </div>
          </div>

<!-- Paper abstract -->
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Optical Coherence Tomography (OCT) is a novel and effective screening tool for ophthalmic examination. Since collecting OCT images is relatively more expensive than fundus photographs, existing methods use multi-modal learning to complement limited OCT data with additional context from fundus images. However, the multi-modal framework requires eye-paired datasets of both modalities, which is impractical for clinical use. To address this problem, we propose a novel fundus-enhanced disease-aware distillation model (FDDM), for retinal disease classification from OCT images. Our framework enhances the OCT model during training by utilizing unpaired fundus images and does not require the use of fundus images during testing, which greatly improves the practicality and efficiency of our method for clinical use. Specifically, we propose a novel class prototype matching to distill disease-related information from the fundus model to the OCT model and a novel class similarity alignment to enforce consistency between disease distribution of both modalities. Experimental results show that our proposed approach outperforms single-modal, multi-modal, and stateof-the-art distillation methods for retinal disease classification.
          </p>
        </div>

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/method-finalv2.pdf" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Overview of our proposed FDDM. Our method is based on class prototype matching, which distills disease-specific features, and class similarity alignment, which distills inter-class relationships.
        </h2>
      </div>
  </div>
</div>
</div>
</section>

      </div>
    </div>
  </div>
  </div>
</section>



  </body>
  </html>
